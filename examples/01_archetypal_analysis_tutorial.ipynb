{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ArchetypAX: Basic Usage Example\n",
    "\n",
    "This notebook demonstrates the fundamental capabilities of ArchetypAX, a GPU-accelerated implementation of Archetypal Analysis using JAX.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from scipy.spatial import ConvexHull\n",
    "\n",
    "sys.path.insert(0, os.path.abspath(\"../\"))\n",
    "\n",
    "from archetypax.models import ImprovedArchetypalAnalysis as ArchetypalAnalysis\n",
    "from archetypax.tools.evaluation import ArchetypalAnalysisEvaluator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generating Synthetic Data\n",
    "\n",
    "We'll start by creating a synthetic dataset with clear cluster structure to demonstrate the effectiveness of archetypal analysis.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate synthetic data with 3 clusters\n",
    "np.random.seed(42)\n",
    "n_samples = 5000\n",
    "n_centers = 3  # Number of clusters\n",
    "\n",
    "# Create 3 clusters with some overlap\n",
    "cluster1 = np.random.randn(n_samples // 3, 2) * 0.5 + np.array([2, 2])\n",
    "cluster2 = np.random.randn(n_samples // 3, 2) * 0.5 + np.array([-2, 2])\n",
    "cluster3 = np.random.randn(n_samples // 3, 2) * 0.5 + np.array([0, -2])\n",
    "\n",
    "# Create corresponding labels for each cluster\n",
    "y1 = np.zeros(n_samples // 3)\n",
    "y2 = np.ones(n_samples // 3)\n",
    "y3 = np.ones(n_samples // 3) * 2\n",
    "\n",
    "# Combine data and labels simultaneously\n",
    "X = np.vstack([cluster1, cluster2, cluster3])\n",
    "y = np.concatenate([y1, y2, y3])\n",
    "\n",
    "# Shuffle data and labels together to maintain correspondence\n",
    "indices = np.arange(X.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "X = X[indices]\n",
    "y = y[indices]\n",
    "\n",
    "print(f\"Data shape: {X.shape}\")\n",
    "\n",
    "# Visualize the data\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"viridis\", alpha=0.7, s=50)\n",
    "plt.title(\"Synthetic Dataset with 3 Clusters\", fontsize=14)\n",
    "plt.xlabel(\"Feature 1\", fontsize=12)\n",
    "plt.ylabel(\"Feature 2\", fontsize=12)\n",
    "plt.colorbar(label=\"Cluster\")\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Fitting the Archetypal Analysis Model\n",
    "\n",
    "Now we'll apply ArchetypAX to identify the archetypes in our data. We'll set the number of archetypes to match our known number of clusters.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize and fit the model\n",
    "model = ArchetypalAnalysis(\n",
    "    n_archetypes=3,\n",
    "    max_iter=1000,\n",
    "    tol=1e-10,\n",
    "    learning_rate=0.001,\n",
    "    lambda_reg=0.01,\n",
    "    normalize=False,\n",
    "    projection_alpha=0.2,\n",
    "    projection_method=\"cbap\",\n",
    "    archetype_init_method=\"directional\",\n",
    "    random_seed=42,\n",
    "    verbose_level=1,\n",
    ")\n",
    "weights = model.fit_transform(\n",
    "    X,\n",
    "    method=\"adam\",\n",
    "    max_iter=1000,\n",
    ")\n",
    "\n",
    "# Display the loss history\n",
    "loss_history = model.get_loss_history()\n",
    "plt.figure(figsize=(10, 5))\n",
    "plt.plot(loss_history)\n",
    "plt.title(\"Convergence of Archetypal Analysis\", fontsize=14)\n",
    "plt.xlabel(\"Iteration\", fontsize=12)\n",
    "plt.ylabel(\"Loss\", fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the convex hull of the archetypes\n",
    "hull = ConvexHull(model.archetypes, qhull_options='QJ')\n",
    "\n",
    "# Get the volume of the convex hull\n",
    "hull_volume = hull.volume\n",
    "\n",
    "# Display the volume\n",
    "print(f\"Convex hull volume of the archetypes: {hull_volume:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "thresh = 0.0\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "_weights = model.weights[np.max(model.weights, axis=1) > thresh]\n",
    "sns.heatmap(_weights[:30], cmap=\"viridis\", annot=True, fmt=\".2f\")\n",
    "plt.title(\"Sample of archetype weights from the last iteration\")\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(10, 10))\n",
    "_weights = weights[np.max(weights, axis=1) > thresh]\n",
    "sns.heatmap(_weights[:30], cmap=\"viridis\", annot=True, fmt=\".2f\")\n",
    "plt.title(\"Sample of archetype weights from the transformed data\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Visualizing the Archetypes\n",
    "\n",
    "Let's visualize the identified archetypes in relation to our data points.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract the archetypes\n",
    "archetypes = model.archetypes\n",
    "\n",
    "# Visualize data points and archetypes\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=y, cmap=\"viridis\", alpha=0.6, s=40, label=\"Data points\")\n",
    "plt.scatter(\n",
    "    archetypes[:, 0], archetypes[:, 1], c=\"red\", s=200, marker=\"*\", edgecolor=\"black\", linewidth=1.5, label=\"Archetypes\"\n",
    ")\n",
    "\n",
    "# Add archetype indices\n",
    "for i, (_x, _y) in enumerate(archetypes):\n",
    "    plt.annotate(f\"A{i + 1}\", (_x, _y), fontsize=14, fontweight=\"bold\", xytext=(10, 10), textcoords=\"offset points\")\n",
    "\n",
    "plt.title(\"Data Points and Identified Archetypes\", fontsize=14)\n",
    "plt.xlabel(\"Feature 1\", fontsize=12)\n",
    "plt.ylabel(\"Feature 2\", fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Analyzing Archetype Weights\n",
    "\n",
    "Each data point is represented as a convex combination of the archetypes. Let's visualize these weights.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a colormap based on the dominant archetype for each point\n",
    "dominant_archetypes = np.argmax(weights, axis=1)\n",
    "\n",
    "# Visualize data points colored by their dominant archetype\n",
    "plt.figure(figsize=(12, 8))\n",
    "plt.scatter(X[:, 0], X[:, 1], c=dominant_archetypes, cmap=\"Set1\", alpha=0.7, s=50)\n",
    "plt.scatter(\n",
    "    archetypes[:, 0],\n",
    "    archetypes[:, 1],\n",
    "    c=\"black\",\n",
    "    s=150,\n",
    "    marker=\"*\",\n",
    "    edgecolor=\"white\",\n",
    "    linewidth=1.5,\n",
    "    label=\"Archetypes\",\n",
    ")\n",
    "\n",
    "# Add archetype indices\n",
    "for i, (_x, _y) in enumerate(archetypes):\n",
    "    plt.annotate(f\"A{i + 1}\", (_x, _y), fontsize=14, fontweight=\"bold\", xytext=(10, 10), textcoords=\"offset points\")\n",
    "\n",
    "plt.title(\"Data Points Colored by Dominant Archetype\", fontsize=14)\n",
    "plt.xlabel(\"Feature 1\", fontsize=12)\n",
    "plt.ylabel(\"Feature 2\", fontsize=12)\n",
    "plt.legend(fontsize=12)\n",
    "plt.grid(alpha=0.3)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Evaluating the Model\n",
    "\n",
    "Let's use the ArchetypalAnalysisEvaluator to assess the quality of our model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the evaluator\n",
    "evaluator = ArchetypalAnalysisEvaluator(model)\n",
    "\n",
    "# Calculate reconstruction error\n",
    "frobenius_error = evaluator.reconstruction_error(X, metric=\"frobenius\")\n",
    "relative_error = evaluator.reconstruction_error(X, metric=\"relative\")\n",
    "mse_error = evaluator.reconstruction_error(X, metric=\"mse\")\n",
    "\n",
    "# Calculate explained variance\n",
    "explained_var = evaluator.explained_variance(X)\n",
    "\n",
    "# Calculate archetype purity\n",
    "purity_results = evaluator.dominant_archetype_purity()\n",
    "\n",
    "# Calculate archetype separation\n",
    "separation_results = evaluator.archetype_separation()\n",
    "\n",
    "# Display results\n",
    "print(f\"Reconstruction Error (Frobenius): {frobenius_error:.4f}\")\n",
    "print(f\"Reconstruction Error (Relative): {relative_error:.4f}\")\n",
    "print(f\"Reconstruction Error (MSE): {mse_error:.4f}\")\n",
    "print(f\"Explained Variance: {explained_var:.4f}\")\n",
    "print(f\"Overall Archetype Purity: {purity_results['overall_purity']:.4f}\")\n",
    "print(f\"Archetype Separation (Mean Distance): {separation_results['mean_distance']:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Visualizing the Reconstruction\n",
    "\n",
    "Let's compare the original data with its reconstruction using the archetypes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reconstruct the data\n",
    "X_reconstructed = model.reconstruct()\n",
    "X_reconstructed = weights @ archetypes\n",
    "\n",
    "# Visualize original vs reconstructed data\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 6))\n",
    "\n",
    "# Original data\n",
    "ax1.scatter(X[:, 0], X[:, 1], c=y, cmap=\"viridis\", alpha=0.7, s=50)\n",
    "ax1.scatter(\n",
    "    archetypes[:, 0],\n",
    "    archetypes[:, 1],\n",
    "    c=\"red\",\n",
    "    s=200,\n",
    "    marker=\"*\",\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1.5,\n",
    "    label=\"Archetypes\",\n",
    ")\n",
    "ax1.set_title(\"Original Data\", fontsize=14)\n",
    "ax1.set_xlabel(\"Feature 1\", fontsize=12)\n",
    "ax1.set_ylabel(\"Feature 2\", fontsize=12)\n",
    "ax1.grid(alpha=0.3)\n",
    "ax1.legend(fontsize=12)\n",
    "\n",
    "# Reconstructed data\n",
    "ax2.scatter(X_reconstructed[:, 0], X_reconstructed[:, 1], c=y, cmap=\"viridis\", alpha=0.7, s=50)\n",
    "ax2.scatter(\n",
    "    archetypes[:, 0],\n",
    "    archetypes[:, 1],\n",
    "    c=\"red\",\n",
    "    s=200,\n",
    "    marker=\"*\",\n",
    "    edgecolor=\"black\",\n",
    "    linewidth=1.5,\n",
    "    label=\"Archetypes\",\n",
    ")\n",
    "\n",
    "# Connect archetype points with lines to enhance visualization\n",
    "# Create a convex hull by connecting the archetypes\n",
    "hull = ConvexHull(archetypes)\n",
    "for simplex in hull.simplices:\n",
    "    ax2.plot(archetypes[simplex, 0], archetypes[simplex, 1], \"r-\", alpha=0.6, linewidth=2)\n",
    "\n",
    "ax2.set_title(\"Reconstructed Data\", fontsize=14)\n",
    "ax2.set_xlabel(\"Feature 1\", fontsize=12)\n",
    "ax2.set_ylabel(\"Feature 2\", fontsize=12)\n",
    "ax2.legend(fontsize=12)\n",
    "ax2.grid(alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Visualizing Weight Distribution\n",
    "\n",
    "Let's examine how the weights are distributed across the archetypes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a DataFrame for the weights\n",
    "weights_df = pd.DataFrame(weights, columns=[f\"Archetype {i + 1}\" for i in range(model.n_archetypes)])\n",
    "\n",
    "# Plot the distribution of weights\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=weights_df)\n",
    "plt.title(\"Distribution of Archetype Weights\", fontsize=14)\n",
    "plt.ylabel(\"Weight Value\", fontsize=12)\n",
    "plt.grid(axis=\"y\", alpha=0.3)\n",
    "plt.show()\n",
    "\n",
    "# Plot the correlation between weights\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(weights_df.corr(), annot=True, cmap=\"coolwarm\", vmin=-1, vmax=1, center=0)\n",
    "plt.title(\"Correlation Between Archetype Weights\", fontsize=14)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Conclusion\n",
    "\n",
    "This notebook has demonstrated the basic usage of ArchetypAX for archetypal analysis. We've shown how to:\n",
    "\n",
    "1. Fit an archetypal analysis model to data\n",
    "2. Visualize the identified archetypes\n",
    "3. Analyze the weight distributions\n",
    "4. Evaluate the model's performance\n",
    "5. Reconstruct the data using the archetypes\n",
    "\n",
    "Archetypal analysis provides an interpretable representation of data by identifying extreme, yet representative points (archetypes) and expressing each data point as a mixture of these archetypes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
